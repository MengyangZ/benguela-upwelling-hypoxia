{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842cdc5-b640-4f4f-a9a8-c80421b2335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "\n",
    "import cmocean\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy import spatial\n",
    "from glob import glob\n",
    "\n",
    "import gsw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f53ba06-e7a1-4a34-9c15-2b5ade2baaf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SHB map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fa7b2d-f60e-4a65-93c1-d1e7cbf17537",
   "metadata": {},
   "source": [
    "Obtain bathymetric data. You can use public datasets such as NOAA's ETOPO1. Download the data from: https://www.ngdc.noaa.gov/mgg/global/ and select the \"ETOPO1 Global Relief Model\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098fe4c-bf77-489e-8059-eb9f4a07b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_map = xr.open_dataset('./data/ETOPO_2022_v1_60s_N90W180_bed.nc')\n",
    "\n",
    "lon_min, lon_max = 14, 20\n",
    "lat_min, lat_max =  -35, -29\n",
    "\n",
    "da_sub = da_map.sel(lat=slice(lat_min, lat_max), lon= slice(lon_min, lon_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2e347-6cb8-4b98-b61d-103819ab432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model grid from Fearon et al 2023\n",
    "da = xr.open_dataset('./data/grid.nc')\n",
    "earlySHBML = pd.read_pickle('./data/earlySHBML.pkl')\n",
    "\n",
    "tlong = da.lon_rho.values\n",
    "tlat = da.lat_rho.values\n",
    "mask = da.mask_rho.isel(time=0).values\n",
    "inshore_mask = xr.where(da.isel(time=0).h <= 100, 1, 0)  # inshore of 100m\n",
    "mask_sel = mask*inshore_mask\n",
    "\n",
    "ocean_indices = np.where(mask_sel==1)\n",
    "tlong_sel = tlong[ocean_indices]\n",
    "tlat_sel = tlat[ocean_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78f9c1-1120-494d-a94d-6b9f960c5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map(ax):\n",
    "\n",
    "    ax.set_extent([17, 18.5, -33.5, -31], crs=ccrs.PlateCarree())\n",
    "\n",
    "    ax.set_xticks(np.arange(16.1, 19.5, 0.7), crs=ccrs.PlateCarree())\n",
    "    ax.set_yticks(np.arange(-33.5, -30.5, 0.5), crs=ccrs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)  \n",
    "\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "\n",
    "    colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "    ind_color = np.arange(len(colors)) # 0- 9\n",
    "\n",
    "    edges_coord = []\n",
    "\n",
    "    # water depth\n",
    "    ca = da_sub.z.plot.contourf(ax=ax, levels=20, transform=ccrs.PlateCarree(), add_colorbar=False, alpha=0.5)\n",
    "\n",
    "    # edges\n",
    "    corners_long = [tlong[0, 0], tlong[0, -1], tlong[-1, -1], tlong[-1, 0], tlong[0, 0]]\n",
    "    corners_lat = [tlat[0, 0], tlat[0, -1], tlat[-1, -1], tlat[-1, 0], tlat[0, 0]]\n",
    "\n",
    "    # Plot the corners and connect them\n",
    "    ax.plot(corners_long, corners_lat, '--', color='C3', alpha=0.7, )\n",
    "\n",
    "    ax.scatter(tlong_sel, tlat_sel, c='gray', s=1, alpha=0.1, transform=ccrs.PlateCarree())\n",
    "    \n",
    "    mask = ~( (earlySHBML.Latitude < -32.6) & (earlySHBML.Longitude > 17.5) )\n",
    "    ax.scatter(earlySHBML.Longitude[mask], earlySHBML.Latitude[mask], marker='o', s=20, color= 'k', transform=ccrs.PlateCarree(), label='SHBML')\n",
    "\n",
    "    moor20m = [18.318, -32.292]\n",
    "    ax.scatter(moor20m[0], moor20m[1], marker='^', color= 'r', s=80, transform=ccrs.PlateCarree(), label='20m mooring')\n",
    "\n",
    "    # coordinate of 70 m mooring\n",
    "    moor70m = [18.183, -32.329]\n",
    "    ax.scatter(moor70m[0], moor70m[1], marker='*', color= 'r', s=80, transform=ccrs.PlateCarree(), label='70m mooring')\n",
    "\n",
    "    # contour\n",
    "    contours = ax.contour(da.lon_rho, da.lat_rho, da.isel(time=0).h, \n",
    "                          levels=5, colors='black', linewidths=1.5, alpha=0.8)\n",
    "    plt.clabel(contours, inline=True, fontsize=9)\n",
    "\n",
    "    ax.legend(loc='lower left', fontsize=10)\n",
    "\n",
    "    ax.text(18.35, -31.8, 'South \\nAfrica')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig = plt.figure(figsize=(5, 6))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "plot_map(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e288fb-98ce-4157-9fa4-403004095db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the water depth of 20m and 70m moorings\n",
    "\n",
    "def find_point(lat_1 = 73.297, lon_1 = -145.456):\n",
    "\n",
    "    # Flatten the 2D lat/lon grids\n",
    "    lat_flat = da.lat_rho.values.ravel()\n",
    "    lon_flat = da.lon_rho.values.ravel()\n",
    "    \n",
    "    dist = np.empty(shape=lat_flat.shape)\n",
    "    \n",
    "    for p in range(len(dist)):\n",
    "        dist[p] = gsw.distance([lon_flat[p], lon_1], [lat_flat[p], lat_1])  \n",
    "        \n",
    "    # Find index of minimum distance\n",
    "    idx_flat = np.nanargmin(dist)\n",
    "    \n",
    "    # Convert back to 2D indices\n",
    "    i, j = np.unravel_index(idx_flat, da.lat_rho.shape)\n",
    "    \n",
    "    print(f\"Closest point index: nlat={i}, nlon={j}\")\n",
    "    print(f\"Coordinates: lat={da.lat_rho.values[i,j]}, lon={da.lon_rho.values[i,j]}\")\n",
    "\n",
    "    return i, j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73a784-6590-479b-851e-234956c0f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "moor20m = [18.318, -32.292]\n",
    "moor70m = [18.183, -32.329]\n",
    "\n",
    "i_20, j_20 = find_point(lat_1 = moor20m[1], lon_1 = moor20m[0])\n",
    "i_70, j_70 = find_point(lat_1 = moor70m[1], lon_1 = moor70m[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c9a4c-5154-4953-820d-b0ba0c4b261f",
   "metadata": {},
   "source": [
    "# Dissolved oxygen climatology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6871468-f45a-449c-a7cc-7442d71b6762",
   "metadata": {},
   "source": [
    "Pre-processing climatology data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90888b84-e493-4021-8fb7-296ddcc2092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SHBML climatology data (de Villiers, 2017) are available from: https://doi.pangaea.de/10.1594/PANGAEA.882218\n",
    "fpath = './data/Climatology_SBUS.csv'\n",
    "df = pd.read_csv(fpath, encoding='latin1')\n",
    "\n",
    "l_vars = list(df.columns) # names of all the variables\n",
    "var = ['Temp', 'Sal', 'O2', '[PO4]3-', '[NO3]- + [NO2]-', 'Si(OH)4', 'Chl a']\n",
    "months = [\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2099f-1eb5-4efa-8657-a3a15f6a229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_stn(stn):\n",
    "    '''for a station, return a dataset with all variables'''\n",
    "\n",
    "    df_sub = df[df['Station'] == stn]\n",
    "    # extract longitude and latitude\n",
    "    depth = df_sub['Depth water [m]'].values # depth array\n",
    "    num_depth = np.size(depth) # number of depth levels\n",
    "\n",
    "    all_data = [] # collect data from all variables\n",
    "    for v in var:\n",
    "        #v = var[0] # the variable\n",
    "        v_12months = np.empty((num_depth, 12)) # initialized the array for 12 months' data\n",
    "        for i in range(12):\n",
    "            # find the variable name that has both the variable and the month\n",
    "            selected_var = [s for s in l_vars if (v in s) and (months[i] in s)][0]\n",
    "\n",
    "            v_12months[:, i] = df_sub[selected_var].values\n",
    "        all_data.append(v_12months)\n",
    "\n",
    "    # form a dataset\n",
    "    variables_dict = {f'{v}': (['depth', 'month'], d) for v, d in zip(var, all_data)}\n",
    "    ds_ = xr.Dataset(\n",
    "        variables_dict,\n",
    "        coords={'month': np.arange(1,13,1),\n",
    "                'depth': depth,\n",
    "               },\n",
    "    )\n",
    "    ds_ = ds_.expand_dims({'station': [stn]})\n",
    "    \n",
    "    return ds_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9d47c-f6d0-4f8b-8daa-747315fd787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitch all stations together\n",
    "stations = df['Station'].unique()\n",
    "\n",
    "ds = None\n",
    "for stn in stations:  \n",
    "    stn = int(stn) # needs to be int to be iterable\n",
    "    try:\n",
    "        ds = xr.concat([ds, get_ds_stn(stn)], 'station')    \n",
    "    except:\n",
    "        ds = get_ds_stn(stn)\n",
    "ds = ds.rename({'Temp': 'temp', \n",
    "                'Sal': 'sal', \n",
    "                'O2': 'oxy',\n",
    "                '[PO4]3-': 'phos',\n",
    "                '[NO3]- + [NO2]-': 'nitrate', \n",
    "                'Si(OH)4': 'silicate', \n",
    "                'Chl a': 'chl', \n",
    "               })\n",
    "# add units for each variable\n",
    "units_dict = {'temp': 'degC',\n",
    "              'depth': 'm',\n",
    "              'sal': 'psu',\n",
    "              'oxy': 'µmol/l',\n",
    "              'phos': 'µmol/l',\n",
    "              'nitrate': 'µmol/l',\n",
    "              'silicate': 'µmol/l',\n",
    "              'chl': 'µg/l'\n",
    "             }\n",
    "\n",
    "# Loop over variable names and set units\n",
    "for var_name, units in units_dict.items():\n",
    "    ds[var_name].attrs['units'] = units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e7dc4-517a-42b1-811e-fb70b316fff8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f5293a-f79e-41e9-9ab3-f8e7734fb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords for stations\n",
    "lat_ = df['Latitude'].unique()\n",
    "lon_ = df['Longitude'].unique()\n",
    "\n",
    "# distance from station 1\n",
    "dist = np.cumsum(gsw.distance(lon_, lat_))/1000 # km\n",
    "dist = np.insert(dist, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6074a-f4ba-4632-bdf8-cf81dd0d57a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sharp_gradients(arr, threshold):\n",
    "    \n",
    "    '''replace the all values after the sharp gradient to NaN'''\n",
    "    \n",
    "    # Compute the gradient\n",
    "    gradient = np.diff(arr)\n",
    "    \n",
    "    # Find the indices where the gradient exceeds the threshold\n",
    "    sharp_points = np.where(np.abs(gradient) > threshold)[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if sharp_points.size == 0:\n",
    "        return arr\n",
    "    else:\n",
    "        arr[sharp_points[0]:] = np.nan\n",
    "    #return sharp_points\n",
    "        return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5df6aa-4406-4fc6-8b70-0f668dbc4500",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Interpolate into a trasect with profiles every 1km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370289d7-d562-4c9d-846c-9dab38c518af",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_new_nan = np.empty((366, 150, 12))\n",
    "\n",
    "for m in range(12):\n",
    "    \n",
    "    # Original data\n",
    "    A_ = ds.oxy.values[:,:,m]\n",
    "    A = np.nan_to_num(A_, nan=-999)\n",
    "    x_original = dist\n",
    "    y = ds.depth.values\n",
    "    # Create the interpolation function\n",
    "    f = interp2d(x_original, y, A.T, kind='linear')\n",
    "    # New x-axis\n",
    "    x_new = np.arange(0, 150)\n",
    "    # Interpolate A to the new grid\n",
    "    A_new = f(x_new, y)\n",
    "    \n",
    "    print(m, A_new.shape)\n",
    "\n",
    "\n",
    "    for i in range(A_new.shape[1]):\n",
    "\n",
    "        A_new_nan[:, i, m] = detect_sharp_gradients(A_new[:, i], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b054ddcd-3bc7-4c7a-8c58-d8b02103028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_transect_interpolated = xr.Dataset(\n",
    "    {\n",
    "        'oxy': (['depth', 'dist2shore',  'month'], A_new_nan),\n",
    "\n",
    "    },\n",
    "    coords={\n",
    "            'dist2shore': np.arange(0,150),\n",
    "            'depth': ds.depth.values,\n",
    "            'month': ds.month.values,\n",
    "           },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fbb892-9d16-4683-a318-c38421d822b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.contourf(dist, ds.depth, ds.oxy.isel(month=0).T, levels=np.arange(14,302, 20))\n",
    "plt.ylim(366,0)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Distance from shore (km)')\n",
    "plt.ylabel('Depth (m)')\n",
    "plt.title('Original')\n",
    "\n",
    "for stn in range(ds.station.size):\n",
    "    ind = ~np.isnan(ds.oxy.isel(month=0, station=stn).values)\n",
    "    x_ = ind*dist[stn]\n",
    "    plt.scatter(x_[ind], ds.depth.values[ind], c='gray', s=2)\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.contourf(DO_transect_interpolated.dist2shore, DO_transect_interpolated.depth, DO_transect_interpolated.oxy.isel(month=0), levels=np.arange(14,302, 20))\n",
    "plt.ylim(366,0)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Distance from shore (km)')\n",
    "plt.ylabel('Depth (m)')\n",
    "plt.title('Interpolated for every 1 km')\n",
    "\n",
    "for stn in range(DO_transect_interpolated.dist2shore.size):\n",
    "    if stn%2==0:\n",
    "        ind = ~np.isnan(DO_transect_interpolated.oxy.isel(month=0, dist2shore=stn).values)\n",
    "        x_ = ind*DO_transect_interpolated.dist2shore.values[stn]\n",
    "        plt.scatter(x_[ind], DO_transect_interpolated.depth.values[ind], c='gray', s=1, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7bf2b4-cc0b-40fc-b2b4-8d42090c3ff8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Interpolate coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5281e190-e60b-4026-bc56-deba1bd2ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original 1D array of longitudes with 12 elements\n",
    "longitudes = df['Longitude'].unique() \n",
    "latitudes = df['Latitude'].unique()\n",
    "\n",
    "# Create an array with 150 elements for the new grid\n",
    "new_x = np.linspace(0, len(longitudes) - 1, 150)\n",
    "\n",
    "interpolated_longitudes = np.interp(new_x, np.arange(len(longitudes)), longitudes)\n",
    "interpolated_latitudes = np.interp(new_x, np.arange(len(latitudes)), latitudes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67988a69-ee90-41ba-971d-ca7a0c5c66ff",
   "metadata": {},
   "source": [
    "Check they match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5178de91-fc03-4aaf-b26c-51ac1b3daac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, len(longitudes) -1 , 150), interpolated_longitudes)\n",
    "plt.plot(np.linspace(0, len(longitudes) -1 , 10), longitudes, '--')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(np.linspace(0, len(longitudes) -1 , 150), interpolated_latitudes)\n",
    "plt.plot(np.linspace(0, len(longitudes) -1 , 10), latitudes, '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414738c8-5a8a-4e44-b777-8bef51147038",
   "metadata": {},
   "source": [
    "Read model bathymetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dcf8ab-ab2d-4702-94ce-1659f658321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_giles = xr.open_mfdataset('./data/croco_grd.nc')\n",
    "\n",
    "tlong_bth = da_giles.lon_rho.values\n",
    "tlat_bth = da_giles.lat_rho.values\n",
    "h_bth = da_giles.h.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5934a-aa2d-41a2-9dd3-53de4b51944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target points\n",
    "target_lons = interpolated_longitudes\n",
    "target_lats = interpolated_latitudes\n",
    "\n",
    "closest_indices = []\n",
    "\n",
    "for lon_point, lat_point in zip(target_lons, target_lats):\n",
    "    # Calculate the squared distance for efficiency\n",
    "    distances = (tlong_bth - lon_point)**2 + (tlat_bth - lat_point)**2\n",
    "    \n",
    "    # Find the index of the minimum distance\n",
    "    idx = np.unravel_index(np.argmin(distances), tlong_bth.shape)\n",
    "    \n",
    "    closest_indices.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875d464-d2a7-43d1-8d0f-08e43eaabe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_sel = []\n",
    "for i in range(len(closest_indices)):\n",
    "    h_sel.append(h_bth[closest_indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f1cd27-355e-41ee-9381-e35db1a0f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(150), h_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe461b-c71b-496f-8ea0-a852024f5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 6))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "ax.set_extent([17, 18.5, -33.5, -31], crs=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_xticks(np.arange(16.3, 19, 0.5), crs=ccrs.PlateCarree())\n",
    "ax.set_yticks(np.arange(-33.5, -30.5, 0.5), crs=ccrs.PlateCarree())\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)  \n",
    "\n",
    "ax.add_feature(cfeature.LAND)\n",
    "\n",
    "# edges\n",
    "corners_long = [tlong_bth[0, 0], tlong_bth[0, -1], tlong_bth[-1, -1], tlong_bth[-1, 0], tlong_bth[0, 0]]\n",
    "corners_lat = [tlat_bth[0, 0], tlat_bth[0, -1], tlat_bth[-1, -1], tlat_bth[-1, 0], tlat_bth[0, 0]]\n",
    "plt.plot(corners_long, corners_lat, '--', color='C3', alpha=0.7, )\n",
    "\n",
    "for i in range(len(closest_indices)):\n",
    "    ax.scatter(tlong_bth[closest_indices[i]], tlat_bth[closest_indices[i]],s=5, c='k', transform=ccrs.PlateCarree())\n",
    "ax.scatter(longitudes, latitudes, s=10, c='r', transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.set_xlabel('Longitude', fontsize=14)\n",
    "ax.set_ylabel('Latitude', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb56961-7e5a-41c8-831a-69bbec197179",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now we have the h, we need to modify DO_transect_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8b856-3606-483e-b582-e03d2d010ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_transect_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7f7f3-e237-4f5f-84ae-6cc71c66e000",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_depth = DO_transect_interpolated.depth.values\n",
    "print('first depth is ', arr_depth[0], ' m')\n",
    "\n",
    "new_oxy = np.copy(DO_transect_interpolated.oxy.values)\n",
    "num_d, num_i, num_t = new_oxy.shape\n",
    "num_d, num_i, num_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979aa15-8290-4eae-b6ec-8f5725573caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(num_t):\n",
    "    for i in range(num_i):\n",
    "            DO_sel = new_oxy[:, i, t]\n",
    "            \n",
    "            # Count the number of non-NaN values\n",
    "            count_non_nan = np.sum(~np.isnan(DO_sel))\n",
    "            \n",
    "            # this is the depth that has a value\n",
    "            depth_with_value = arr_depth[0] + count_non_nan - 1 \n",
    "            \n",
    "            if depth_with_value <= int(h_sel[i]):\n",
    "                \n",
    "                # the depth range to append values\n",
    "                diff_d = int(h_sel[i]) - depth_with_value\n",
    "                \n",
    "                new_oxy[count_non_nan : count_non_nan+diff_d, i, t] = DO_sel[count_non_nan-1]\n",
    "                \n",
    "            elif depth_with_value > int(h_sel[i]):\n",
    "                \n",
    "                # the depth range to append nan\n",
    "                diff_d = - int(h_sel[i]) + depth_with_value\n",
    "                \n",
    "                new_oxy[count_non_nan - diff_d : count_non_nan, i, t] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be31b1ac-cd9b-42d3-a6f2-bef1b4d51a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_transect_interpolated_final = xr.Dataset(\n",
    "    {\n",
    "        'oxy': (['depth', 'dist2shore',  'month'], new_oxy),\n",
    "\n",
    "    },\n",
    "    coords={\n",
    "            'dist2shore': np.arange(0,150),\n",
    "            'depth': ds.depth.values,\n",
    "            'month': ds.month.values,\n",
    "           },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e002af35-377f-4542-be99-43d8c8591a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.contourf(DO_transect_interpolated_final.dist2shore, DO_transect_interpolated_final.depth, DO_transect_interpolated_final.oxy.isel(month=0), levels=np.arange(14,302, 20))\n",
    "plt.ylim(366,0)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Distance from shore (km)')\n",
    "plt.ylabel('Depth (m)')\n",
    "plt.title('Interpolated horizontal and vertical to h')\n",
    "\n",
    "plt.plot(np.arange(150), h_sel, 'r')\n",
    "\n",
    "for stn in range(DO_transect_interpolated_final.dist2shore.size):\n",
    "    if stn%2==0:\n",
    "        ind = ~np.isnan(DO_transect_interpolated_final.oxy.isel(month=0, dist2shore=stn).values)\n",
    "        x_ = ind*DO_transect_interpolated_final.dist2shore.values[stn]\n",
    "        plt.scatter(x_[ind], DO_transect_interpolated_final.depth.values[ind], c='gray', s=1, alpha=0.1)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.contourf(DO_transect_interpolated.dist2shore, DO_transect_interpolated.depth, DO_transect_interpolated.oxy.isel(month=0), levels=np.arange(14,302, 20))\n",
    "plt.ylim(366,0)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Distance from shore (km)')\n",
    "plt.ylabel('Depth (m)')\n",
    "plt.title('Interpolated for every 1 km')\n",
    "\n",
    "plt.plot(np.arange(150), h_sel, 'r')\n",
    "\n",
    "for stn in range(DO_transect_interpolated.dist2shore.size):\n",
    "    if stn%2==0:\n",
    "        ind = ~np.isnan(DO_transect_interpolated.oxy.isel(month=0, dist2shore=stn).values)\n",
    "        x_ = ind*DO_transect_interpolated.dist2shore.values[stn]\n",
    "        plt.scatter(x_[ind], DO_transect_interpolated.depth.values[ind], c='gray', s=1, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24037e5e-6125-4b87-a1e0-d1e4eb1e0a08",
   "metadata": {},
   "source": [
    "# Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f48bd-edcd-43b8-8b23-787ad9c00650",
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = np.concatenate((np.arange(9,13), np.arange(1,9)))\n",
    "string_numbers = [str(xt) for xt in xticks]\n",
    "\n",
    "def plot_DO_20m(ax):\n",
    "    \n",
    "    ns_mooring = pd.read_pickle('./data/WQM20m_daily.pkl') \n",
    "    \n",
    "    var_name = 'Oxygen'\n",
    "    ns_mooring['Month'] = ns_mooring.index.month\n",
    "\n",
    "    # reorder months\n",
    "    ns_mooring_copy = ns_mooring.copy()\n",
    "    for i in range(12):\n",
    "        ns_mooring_copy.loc[ns_mooring_copy['Month'] == xticks[i], 'Month'] = str(i+1)\n",
    "    ns_mooring_copy['Month'] = ns_mooring_copy['Month'].astype(int)\n",
    "\n",
    "\n",
    "    # box-and-whisker plot \n",
    "    flierprops = dict(marker='o', markerfacecolor='none', markersize=6, linestyle='none', markeredgecolor='black', markeredgewidth=0.8)\n",
    "    sns.boxplot(ax=ax, x='Month', y=var_name, data=ns_mooring_copy, width=0.5, color='C2', flierprops=flierprops)\n",
    "\n",
    "    # plot medians\n",
    "    monthly_median = ns_mooring_copy.groupby('Month')[var_name].median().reset_index()\n",
    "    ax.plot(np.arange(0,12), (monthly_median[var_name]), marker='o', color='black')\n",
    "\n",
    "    ax.axhline(y=60, linestyle='--',color='gray')\n",
    "    ax.set_xticks(np.arange(12), string_numbers)\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('DO (µmol kg$^{-1}$)')\n",
    "    ax.set_ylim(0, 310)\n",
    "    ax.set_yticks(np.arange(0,310,50));\n",
    "\n",
    "def plot_DO_70m(ax):\n",
    "\n",
    "    mooring_70m = pd.read_pickle('./data/WQM70m_daily.pkl') \n",
    "    var_name = 'Oxygen'\n",
    "    mooring_70m['Month'] = mooring_70m.index.month\n",
    "\n",
    "    # reorder months\n",
    "    mooring_70m_copy = mooring_70m.copy()\n",
    "    xticks_ = np.array([ 9, 10, 11, 2,  3,  4,  5,  6,  7,  8])\n",
    "    string_numbers_ = [str(xt) for xt in xticks_]\n",
    "    for i in range(10):\n",
    "        if i<=2:\n",
    "            mooring_70m_copy.loc[mooring_70m_copy['Month'] == xticks_[i], 'Month'] = str(i+1)\n",
    "        else:\n",
    "            mooring_70m_copy.loc[mooring_70m_copy['Month'] == xticks_[i], 'Month'] = str(i+3)\n",
    "    mooring_70m_copy['Month'] = mooring_70m_copy['Month'].astype(int)\n",
    "\n",
    "    mooring_70m_copy = mooring_70m_copy.append({var_name: np.nan, 'Month': 4}, ignore_index=True)\n",
    "    mooring_70m_copy = mooring_70m_copy.append({var_name: np.nan, 'Month': 5}, ignore_index=True)\n",
    "\n",
    "    # box-and-whisker plot \n",
    "    flierprops = dict(marker='o', markerfacecolor='none', markersize=6, linestyle='none', markeredgecolor='black', markeredgewidth=0.8)\n",
    "    sns.boxplot(ax=ax, x='Month', y=var_name, data=mooring_70m_copy, width=0.5, color='C2', flierprops=flierprops)\n",
    "\n",
    "    # plot medians\n",
    "    monthly_median = mooring_70m_copy.groupby('Month')[var_name].median().reset_index()\n",
    "    ax.plot(np.arange(12), (monthly_median[var_name]), marker='o', color='black')\n",
    "\n",
    "    ax.axhline(y=60, linestyle='--',color='gray')\n",
    "    ax.set_xticks(np.arange(12), string_numbers)\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('DO (µmol kg$^{-1}$)');\n",
    "    ax.set_ylim(0, 310)\n",
    "    ax.set_yticks(np.arange(0,310,50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a171a9f2-c6d9-4965-8d1a-4d1a128b09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12.3})\n",
    "\n",
    "fig = plt.figure(figsize=(13, 3.4), constrained_layout=True)\n",
    "\n",
    "gs = gridspec.GridSpec(\n",
    "    1, 3,\n",
    "    figure=fig,\n",
    "    wspace=0.03\n",
    ")\n",
    "\n",
    "ax1 = plt.subplot(gs[0, 0], projection=ccrs.PlateCarree())\n",
    "ax2 = plt.subplot(gs[0, 1])\n",
    "ax3 = plt.subplot(gs[0, 2])\n",
    "\n",
    "plot_map(ax1)\n",
    "plot_DO_20m(ax2)\n",
    "plot_DO_70m(ax3)\n",
    "\n",
    "ax1.text(15.3, -31, 'a', fontsize=18)\n",
    "ax2.text(-3.2, 310, 'b', fontsize=18)\n",
    "ax3.text(-3.2, 310, 'c', fontsize=18)\n",
    "\n",
    "#fig.savefig('./figures/figure_1_half.png', dpi=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b14be-5055-4f30-828a-03408220b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_area_hypoxia = []\n",
    "\n",
    "plt.rcParams.update({'font.size': 12.3})\n",
    "\n",
    "def add_colorbar(x0, y0, vmin, vmax, label, cmap_label='rainbow_r', levels=np.arange(0, 300, 30)):\n",
    "    '''\n",
    "    x0, y0: start location for the colorbar\n",
    "    vmin, vmax: range of the colorbar\n",
    "    label: label of the colorbar\n",
    "    levels: discrete levels for the colorbar\n",
    "    '''\n",
    "    cax = fig.add_axes([x0, y0, 0.01, 0.7])  # [x0, y0, width, height]\n",
    "    \n",
    "    # Create a colormap and normalization based on the levels\n",
    "    cmap = plt.get_cmap(cmap_label, len(levels) - 1)  # get discrete colormap\n",
    "    norm = BoundaryNorm(levels, ncolors=cmap.N, clip=True)\n",
    "\n",
    "    # Create the ScalarMappable with the discrete colormap and norm\n",
    "    sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # Needed for the colorbar\n",
    "\n",
    "    # Create the colorbar\n",
    "    cbar = fig.colorbar(sm, cax=cax, shrink=0.9, label=label, orientation='vertical')\n",
    "    #cbar.ax.tick_params(labelsize=18)\n",
    "    cbar.set_ticks(levels)  # Set the ticks to match the levels\n",
    "\n",
    "order = [9,10,11,12,1,2,3,4,5,6,7,8]\n",
    "\n",
    "fig = plt.figure(figsize=(13, 3.4))\n",
    "\n",
    "for t in range(12):\n",
    "    ax = fig.add_subplot(2, 6, t+1)\n",
    "    \n",
    "    data = DO_transect_interpolated_final.oxy.sel(month=order[t])\n",
    "    x = DO_transect_interpolated_final.dist2shore.values\n",
    "    y = DO_transect_interpolated_final.depth.values\n",
    "    plt.contourf(x, y, data, levels=np.arange(0,300, 10), cmap='rainbow_r') # cmap=cmocean.cm.oxy\n",
    "    contours = plt.contour(x, y, data, levels=np.arange(0,300, 60), colors='gray', linestyles='solid', linewidths=1) # cmap=cmocean.cm.oxy\n",
    "    plt.clabel(contours, inline=True, fontsize=10, fmt='%1.0f')\n",
    "    \n",
    "    # hypoxia line\n",
    "    contour_line = plt.contour(x, y, data, levels=[60], colors='black', linestyles='dashed', linewidths=2)\n",
    "    plt.clabel(contour_line, inline=True, fontsize=10, fmt='%1.0f')\n",
    "    \n",
    "    plt.text(78, 280,  f\"Month {order[t]}\")\n",
    "            \n",
    "    ax.set_ylim(370,0)\n",
    "    ax.set_yticks([])\n",
    "    if t in [0,6]:\n",
    "        ax.set_yticks(np.arange(300, -40, -100))\n",
    "        ax.set_ylabel('Depth (m)')\n",
    "    if t >= 6:\n",
    "        ax.set_xticks(np.arange(0, 150, 50))\n",
    "    if t < 6:\n",
    "        ax.set_xticks([])\n",
    "\n",
    "    plt.gca().invert_xaxis()\n",
    "\n",
    "ax.text(550, 500, 'Offshore distance (km)')\n",
    "ax.text(1010, -370, 'd', fontsize=18)\n",
    "\n",
    "add_colorbar(0.91, 0.15, 0, 300, 'DO (µmol kg$^{-1}$)')\n",
    "plt.subplots_adjust(wspace=0.06, hspace=0.05)\n",
    "\n",
    "#fig.savefig(f'./figures/figure1_half2.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28272de-a15f-46d7-809c-65976d17da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two halves of Figure 1\n",
    "from PIL import Image\n",
    "\n",
    "img1 = Image.open('./figures/figure1_half.png')\n",
    "img2 = Image.open('./figures/figure1_half2.png')\n",
    "\n",
    "if img1.width != img2.width:\n",
    "    img2 = img2.resize((img1.width, int(img2.height * img1.width / img2.width)))\n",
    "\n",
    "combined_height = img1.height + img2.height\n",
    "combined_img = Image.new('RGB', (img1.width, combined_height), (255, 255, 255))\n",
    "\n",
    "combined_img.paste(img1, (0, 0))\n",
    "combined_img.paste(img2, (0, img1.height))\n",
    "\n",
    "combined_img.save('./figures/figure1_combined.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe164fa-19e8-4907-928d-73de9446c716",
   "metadata": {},
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264142fe-e7ea-435f-b9a2-8796e8af0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residence time\n",
    "whole_ds_1poly100m = xr.open_dataset('./data/res_time_sub.nc')\n",
    "whole_ds_1poly100m_noMLD = xr.open_dataset('./data/res_time_whole.nc')\n",
    "\n",
    "# mixed layer depth based on N2 metric\n",
    "N2_mld_all = np.load('./data/mld_5years_N2.npy')\n",
    "whole_ds_1poly100m['MLD_N2'] = (('time', 'eta_rho', 'xi_rho'), N2_mld_all)\n",
    "\n",
    "# stratification\n",
    "ds_stra = xr.open_dataset(f'./data/ds_stratification.nc')\n",
    "ds_slope_adjusted_APG = xr.open_dataset(f'./data/ds_slope_APG_3km_domain_adjusted_closer2shore.nc')\n",
    "\n",
    "# model outputs\n",
    "ns_mdl10m = pd.read_pickle('./data/nearshore_10mextractionsfrom1kmmdl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1cb650-c767-4e81-a8df-7cd4f3d2c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monthly(whole_ds_var):\n",
    "    '''return mean and std of a'''\n",
    "    mean = whole_ds_var.groupby('time.month').mean(dim='time').isel(eta_rho=109, xi_rho=71)\n",
    "    std = whole_ds_var.groupby('time.month').std(dim='time').isel(eta_rho=109, xi_rho=71)\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "def reorder(mean):\n",
    "    return np.concatenate((mean[-4:], mean[:-4]))\n",
    "\n",
    "xticks = np.concatenate((np.arange(9,13), np.arange(1,9)))\n",
    "string_numbers = [str(xt) for xt in xticks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7de32-754c-489f-a717-283dfc397886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std of Tres, Tres_noMLD for inshore of 100m\n",
    "mean_100m, std_100m = get_monthly(whole_ds_1poly100m.efold_time_int)\n",
    "mean_noMLD_100m, std_noMLD_100m = get_monthly(whole_ds_1poly100m_noMLD.efold_time_int)\n",
    "mean_diff_100m, std_diff_100m = get_monthly((whole_ds_1poly100m_noMLD - whole_ds_1poly100m).efold_time_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b38df-d39a-4990-be0f-bb2547cdb863",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "FONTSIZE = 15\n",
    "\n",
    "fig = plt.figure(figsize=(10,7.4))\n",
    "ax0 = fig.add_subplot(2,2, 1)\n",
    "ax1 = fig.add_subplot(2,2, 2)\n",
    "ax2 = fig.add_subplot(2,2, 3)\n",
    "ax3 = fig.add_subplot(2,2, 4)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.15)\n",
    "\n",
    "####### T_res\n",
    "ax = ax0\n",
    "\n",
    "ax.plot(mean_noMLD_100m['month']-1, reorder(mean_noMLD_100m), marker='o', label=r\"$\\tau_{whole}$\", color='C1')\n",
    "ax.fill_between(mean_noMLD_100m['month']-1, reorder(mean_noMLD_100m) - reorder(std_noMLD_100m), reorder(mean_noMLD_100m) + reorder(std_noMLD_100m), alpha=0.2, color='C1')\n",
    "ax.plot(mean_100m['month']-1, reorder(mean_100m), marker='o', label=r\"$\\tau_{sub}$\", color='C0')\n",
    "ax.fill_between(mean_100m['month']-1, reorder(mean_100m) - reorder(std_100m), reorder(mean_100m) + reorder(std_100m), alpha=0.2, color='C0')\n",
    "\n",
    "ax.set_xticks(np.arange(12), string_numbers);\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel(\"Residence times (days)\")\n",
    "ax.set_ylim(2,22)\n",
    "\n",
    "ax.legend(loc='upper left', fontsize=12)\n",
    "\n",
    "\n",
    "######### wind stress\n",
    "ax = ax1\n",
    "var_name = 'svstr'\n",
    "ns_mdl10m['Month'] = ns_mdl10m.index.month\n",
    "# reorder months\n",
    "ns_mdl10m_copy = ns_mdl10m.copy()\n",
    "for i in range(12):\n",
    "    ns_mdl10m_copy.loc[ns_mdl10m_copy['Month'] == xticks[i], 'Month'] = str(i+1)\n",
    "ns_mdl10m_copy['Month'] = ns_mdl10m_copy['Month'].astype(int)\n",
    "\n",
    "# Create a box-and-whisker plot using seaborn\n",
    "flierprops = dict(marker='o', markerfacecolor='none', markersize=6, linestyle='none', markeredgecolor='black', markeredgewidth=0.8)\n",
    "sns.boxplot(ax=ax, x='Month', y=var_name, data=ns_mdl10m_copy, width=0.5, color='C3', flierprops=flierprops)\n",
    "ax.axhline(y=0, color='r', linestyle='--', label='y=0')\n",
    "\n",
    "# plot medians\n",
    "monthly_median = ns_mdl10m_copy.groupby('Month')[var_name].median().reset_index()\n",
    "ax.plot(np.arange(0,12), monthly_median[var_name], marker='o', color='black')\n",
    "ax.set_ylabel(\"Alongshore wind stress (N m$^{-2}$)\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_xticks(np.arange(12), string_numbers);\n",
    "ax.set_yscale('symlog', linthresh=0.01)\n",
    "ax.set_ylim(-0.7, 0.4)\n",
    "\n",
    "tau_monthly_median = monthly_median\n",
    "\n",
    "\n",
    "######## stratification\n",
    "ax= ax2\n",
    "var_name = 'N2_int'\n",
    "var_data = ds_stra[var_name]\n",
    "df = var_data.to_dataframe()\n",
    "df['Month'] = df.index.month\n",
    "# reorder months\n",
    "df_copy = df.copy()\n",
    "for i in range(12):\n",
    "    df_copy.loc[df_copy['Month'] == xticks[i], 'Month'] = str(i+1)\n",
    "df_copy['Month'] = df_copy['Month'].astype(int)\n",
    "\n",
    "flierprops = dict(marker='o', markerfacecolor='none', markersize=6, linestyle='none', markeredgecolor='black', markeredgewidth=0.8)\n",
    "sns.boxplot(ax=ax, x='Month', y=var_name, data=df_copy, width=0.5, color='C4', flierprops=flierprops)\n",
    "\n",
    "# plot medians\n",
    "monthly_median = var_data.groupby('time.month').median('time')\n",
    "ax.plot(np.arange(0,12), reorder(monthly_median), marker='o', color='black')\n",
    "\n",
    "N_monthly_median = monthly_median\n",
    "ax.set_xticks(np.arange(12), string_numbers);\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Bouyancy frequency $N^2$ (rad s$^{-1}$)')\n",
    "\n",
    "\n",
    "######## APG\n",
    "ax = ax3\n",
    "var_name = 'slope'\n",
    "var_data = ds_slope_adjusted_APG[var_name]\n",
    "df = var_data.to_dataframe()\n",
    "df['Month'] = df.index.month\n",
    "# reorder months\n",
    "df_copy = df.copy()\n",
    "for i in range(12):\n",
    "    df_copy.loc[df_copy['Month'] == xticks[i], 'Month'] = str(i+1)\n",
    "df_copy['Month'] = df_copy['Month'].astype(int)\n",
    "\n",
    "flierprops = dict(marker='o', markerfacecolor='none', markersize=6, linestyle='none', markeredgecolor='black', markeredgewidth=0.8)\n",
    "sns.boxplot(ax=ax, x='Month', y=var_name, data=df_copy, width=0.5, color='C5', flierprops=flierprops)\n",
    "\n",
    "# plot median\n",
    "monthly_median = var_data.groupby('time.month').median('time')\n",
    "ax.plot(np.arange(0,12), reorder(monthly_median), marker='o', color='black')\n",
    "ax.plot([-0.5,11.5],[0,0], 'r--')\n",
    "ax.text(3.7, 0.025, 'Poleward')\n",
    "ax.text(3.7, -0.028, 'Equatorward')\n",
    "ax.set_ylim(-0.03, 0.03)\n",
    "# Customize the plot labels and title\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('APG slope (m deg$^{-1}$)')\n",
    "ax.set_xticks(np.arange(12), string_numbers);\n",
    "\n",
    "ax0.text(-1.6, 2.15, 'a', fontsize=18, transform=ax.transAxes)\n",
    "ax1.text(-0.21, 2.15, 'b', fontsize=18, transform=ax.transAxes)\n",
    "ax2.text(-1.6, 1.05, 'c', fontsize=18, transform=ax.transAxes)\n",
    "ax3.text(-0.21, 1.05, 'd', fontsize=18, transform=ax.transAxes)\n",
    "\n",
    "fig.canvas.draw()\n",
    "\n",
    "fig.savefig(f'./figures/figure_3.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae120368-4ba4-47ec-a587-5b075c148db1",
   "metadata": {},
   "source": [
    "# Figure S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b28943-f810-4544-9716-517e46cedbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_equation_from_two_points(point1, point2):\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    \n",
    "    # Calculate slope (m)\n",
    "    slope = (y2 - y1) / (x2 - x1)\n",
    "\n",
    "    # Calculate y-intercept (b) using one of the points\n",
    "    intercept = y1 - slope * x1\n",
    "\n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf8b60-b93c-4d2c-8346-08cb7ca6c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transect coords\n",
    "point1 = (16.9, -29.8)\n",
    "point2 = (18.3, -32.5)\n",
    "\n",
    "k,b = line_equation_from_two_points(point1, point2)\n",
    "print(k,b)\n",
    "\n",
    "xtransect = np.arange(point1[0], point2[0]+0.01, 0.05)\n",
    "ytransect = k*xtransect + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856957b-ca17-4cbc-a042-c57d91d81847",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_3km = xr.open_mfdataset('./data/zeta_avg_3km_Y2008M1.nc')\n",
    "\n",
    "tlong = da_3km.lon_rho.values\n",
    "tlat = da_3km.lat_rho.values\n",
    "mask = da_3km.mask_rho.values\n",
    "\n",
    "ocean_indices = np.where(mask==1)\n",
    "tlong_sel = tlong[ocean_indices]\n",
    "tlat_sel = tlat[ocean_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2c4eab-ca44-4ff5-9bce-cc4342c77f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "fig = plt.figure(figsize=(5, 6))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "\n",
    "ax.set_extent([15.8, 19.5, -35.0, -29.5], crs=ccrs.PlateCarree())\n",
    "ax.set_xticks(np.arange(16, 19, 1), crs=ccrs.PlateCarree())\n",
    "ax.set_yticks(np.arange(-35, -29.5, 1), crs=ccrs.PlateCarree())\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)  \n",
    "\n",
    "ax.add_feature(cfeature.LAND)\n",
    "\n",
    "colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "ind_color = np.arange(len(colors)) # 0- 9\n",
    "\n",
    "edges_coord = []\n",
    "\n",
    "ax.text(18.35, -31.8, 'South \\nAfrica')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "ax.plot(xtransect,ytransect,'k--', linewidth=3)\n",
    "\n",
    "msk = da_3km.mask_rho.values\n",
    "msk[msk == 0] = np.nan\n",
    "ca = ax.contourf(tlong, tlat, da_3km.zeta.isel(time=0) * msk, levels=15, cmap=cm.coolwarm)\n",
    "fig.colorbar(ca, ax=ax, label='Sea surface height (m)', orientation='vertical', shrink=0.7)\n",
    "\n",
    "#fig.savefig(f'./figures/figure_S1.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2961c-c402-45bf-acd1-6b402e2035ef",
   "metadata": {},
   "source": [
    "# Figure S5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10764e87-2695-4567-9784-1ce2d34e6d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std of MLD\n",
    "var_name = 'MLD_N2'\n",
    "var_data = (whole_ds_1poly100m[var_name]*inshore_mask)\n",
    "var_data = xr.where(var_data==0, np.nan, var_data)  # convert 0 to nans\n",
    "var_data = var_data.mean(dim=['eta_rho', 'xi_rho'])\n",
    "MLD_mean =  var_data.groupby('time.month').mean(dim='time')\n",
    "MLD_std =  var_data.groupby('time.month').std(dim='time')\n",
    "\n",
    "Tres_diff_100m = (whole_ds_1poly100m_noMLD-whole_ds_1poly100m).efold_time_int.isel(eta_rho=109, xi_rho=71)\n",
    "mld = var_data\n",
    "\n",
    "x = mld.values\n",
    "y = Tres_diff_100m.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a73274-4c31-4ac5-87d4-136642dbb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "rho, pval = spearmanr(mld, Tres_diff_100m)\n",
    "tau, pval_tau = kendalltau(mld, Tres_diff_100m)\n",
    "\n",
    "print(\"Spearman rho:\", rho, \"p-value:\", pval)\n",
    "print(\"Kendall tau:\", tau, \"p-value:\", pval_tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d04f40-3e7d-4abc-8351-f1c40701517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 11})\n",
    "fig, axes = plt.subplots(1,3, figsize=(11, 2.7))\n",
    "\n",
    "axes[0].plot(mean_diff_100m['month'], reorder(mean_diff_100m), marker='o', label='$\\Delta_{Whole-bottom}$', color='C0')\n",
    "axes[0].fill_between(mean_diff_100m['month'], reorder(mean_diff_100m) - reorder(std_diff_100m), reorder(mean_diff_100m) + reorder(std_diff_100m), alpha=0.2, color='C0')\n",
    "\n",
    "axes[1].plot(MLD_mean['month'], reorder(MLD_mean), marker='o', label='MLD', color='gray')\n",
    "axes[1].fill_between(MLD_mean['month'], reorder(MLD_mean) - reorder(MLD_std), reorder(MLD_mean) + reorder(MLD_std), alpha=0.2, color='gray')\n",
    "\n",
    "\n",
    "axes[0].set_xlabel('Month')\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[0].set_ylabel(r\"$\\tau_{whole}$ - $\\tau_{sub}$ (days)\", fontsize=12)\n",
    "axes[1].set_ylabel('Mixed layer depth (m)')\n",
    "\n",
    "axes[0].set_ylim(2,16)\n",
    "axes[1].set_ylim(0,16)\n",
    "axes[0].set_xticks(np.arange(1,13), string_numbers)\n",
    "axes[1].set_xticks(np.arange(1,13),  string_numbers);\n",
    "axes[0].set_yticks(np.arange(2,17,3));\n",
    "axes[1].set_yticks(np.arange(0,36,5));\n",
    "\n",
    "\n",
    "# Create scatter plot\n",
    "axes[2].scatter(x, y, label='Data Points', s=5, c='lightgray')\n",
    "\n",
    "# Optional: add a LOWESS smoother\n",
    "sns.regplot(x=mld, y=Tres_diff_100m, scatter=False, lowess=True, color='k')\n",
    "\n",
    "# Add labels and legend\n",
    "axes[2].set_xlabel('Mixed layer depth (m)')\n",
    "axes[2].set_ylabel(r\"$\\tau_{whole}$ - $\\tau_{sub}$ (days)\", fontsize=12)\n",
    "\n",
    "Spearman_rho = f'Spearman $\\\\rho$ = {rho:.2f}'\n",
    "p_val = f'p value < 1e-5' \n",
    "\n",
    "axes[2].text(22, 2.5, Spearman_rho, fontsize=10)\n",
    "axes[2].text(25, 1, p_val, fontsize=10)\n",
    "\n",
    "axes[2].set_xlim(-3, 58)\n",
    "axes[2].set_ylim(0, 18)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.0)\n",
    "\n",
    "axes[0].text(-1, 16.5, 'a' , fontsize=15)\n",
    "axes[1].text(-2.5, 36, 'b', fontsize=15)\n",
    "axes[2].text(-10, 18.8, 'c', fontsize=15)\n",
    "\n",
    "#fig.savefig(f'./figures/figure_S5.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6220562d-7c13-4f1d-97ad-b1a230c66d33",
   "metadata": {},
   "source": [
    "# Figure S6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8abfae7-0703-4d10-8faa-6cefa8bdd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_series = ns_mdl10m['svstr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d0b98-e2bf-4e7c-bc48-4a6817adcc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime index and proper naming\n",
    "wind_series.index = pd.to_datetime(wind_series.index)\n",
    "wind_series.name = 'svstr'\n",
    "\n",
    "# Create a DataFrame\n",
    "df = wind_series.to_frame()\n",
    "\n",
    "# Add month columns\n",
    "df['month'] = df.index.month\n",
    "df['month_name'] = df.index.strftime('%b')\n",
    "\n",
    "# Group by month (across all years)\n",
    "grouped = df.groupby('month')\n",
    "\n",
    "# Calculate monthly stats\n",
    "median = grouped['svstr'].median()\n",
    "iqr = grouped['svstr'].quantile(0.75) - grouped['svstr'].quantile(0.25)\n",
    "std = grouped['svstr'].std()\n",
    "\n",
    "# Calculate % upwelling- and downwelling-favorable days\n",
    "upwelling_pct = grouped['svstr'].apply(lambda x: (x > 0).sum() / len(x) * 100)    # positive = upwelling\n",
    "downwelling_pct = grouped['svstr'].apply(lambda x: (x < 0).sum() / len(x) * 100)  # negative = downwelling\n",
    "\n",
    "# Combine into summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Median': median,\n",
    "    'IQR': iqr,\n",
    "    'StdDev': std,\n",
    "    '% Upwelling-Favorable': upwelling_pct,\n",
    "    '% Downwelling-Favorable': downwelling_pct\n",
    "})\n",
    "\n",
    "# Add numeric and name month columns\n",
    "summary['Month'] = summary.index\n",
    "summary['Month Name'] = summary['Month'].apply(lambda x: pd.Timestamp(f'2024-{x:02d}-01').strftime('%b'))\n",
    "\n",
    "# Reorder to start in September (Southern Hemisphere spring)\n",
    "month_order = list(range(9, 13)) + list(range(1, 9))  # [9, 10, 11, 12, 1, ..., 8]\n",
    "summary = summary.set_index('Month')\n",
    "summary = summary.loc[month_order].reset_index()\n",
    "\n",
    "# Update Month Name again (optional)\n",
    "summary['Month Name'] = summary['Month'].apply(lambda x: pd.Timestamp(f'2024-{x:02d}-01').strftime('%b'))\n",
    "\n",
    "# Display result\n",
    "print(summary[['Month Name', 'Median', 'IQR', 'StdDev', '% Upwelling-Favorable', '% Downwelling-Favorable']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96faaebb-85cb-46fc-aac6-6332020b00b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "\n",
    "# Reorder months to start from September\n",
    "month_order = list(range(9, 13)) + list(range(1, 9))\n",
    "summary = summary.set_index('Month')\n",
    "summary = summary.loc[month_order].reset_index()\n",
    "\n",
    "# Use month numbers directly for x-axis labels\n",
    "x_labels = summary['Month'].astype(str).tolist()  # ['9', '10', '11', ..., '8']\n",
    "\n",
    "# Plot\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot median ± IQR (primary axis)\n",
    "ax1.errorbar(x_labels, summary['Median'], \n",
    "             yerr=summary['IQR'] / 2, fmt='o-', label='Median ± IQR', color='C0')\n",
    "\n",
    "ax1.set_ylabel('Alongshore wind stress (N m⁻²)')\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.axhline(0, color='gray', linestyle='--')\n",
    "ax1.set_ylim(-0.04, 0.04)\n",
    "#ax1.grid(True)\n",
    "\n",
    "# Secondary axis for % upwelling and downwelling\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x_labels, summary['% Upwelling-Favorable'], \n",
    "         's--', color='C3', label='% Upwelling-favorable')\n",
    "ax2.plot(x_labels, summary['% Downwelling-Favorable'], \n",
    "         'd--', color='C4', label='% Downwelling-favorable')\n",
    "\n",
    "ax2.set_ylabel('Percentage of days (%)')\n",
    "\n",
    "\n",
    "# Combine legends\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig(f'./figures/figure_S6.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a6d0e-be78-4d3d-9a57-2a80f3521f6e",
   "metadata": {},
   "source": [
    "# Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3226de-482f-445b-8db1-b6fa2da24c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model grid from Fearon et al 2023\n",
    "da = xr.open_dataset('./data/grid.nc')\n",
    "\n",
    "tlong = da.lon_rho.values\n",
    "tlat = da.lat_rho.values\n",
    "mask = da.mask_rho.isel(time=0).values\n",
    "inshore_mask = xr.where(da.isel(time=0).h <= 100, 1, 0)  # inshore of 100m\n",
    "mask_sel = mask*inshore_mask\n",
    "\n",
    "ocean_indices = np.where(mask_sel==1)\n",
    "tlong_sel = tlong[ocean_indices]\n",
    "tlat_sel = tlat[ocean_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f591f12e-3c29-4e61-81fb-fc2997e80375",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_back_30days = xr.open_dataset('./data/back_everyday_result_70m.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b89f2d-b727-4263-89d8-66df7a6c9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(mean):\n",
    "    return np.concatenate((mean[-4:], mean[:-4]))\n",
    "\n",
    "xticks = np.concatenate((np.arange(9,13), np.arange(1,9)))\n",
    "string_numbers = [str(xt) for xt in xticks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b25c13-da56-4ce9-81ec-242d5f7ba5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute trends of depth for each day back in time\n",
    "\n",
    "def plot_depth_mean(index, ax, ax2):\n",
    "    \n",
    "    fpath = '/d1/mengyang/Benguela/Particle_tracking/tempdir/backward_watermass/'\n",
    "    ds_back = xr.open_dataset(fpath + 'back_everyday_result_70m.nc').sel(num_days_back=index)\n",
    "\n",
    "    new_time = np.repeat(ds_back.time, 100).values\n",
    "    new_z = ds_back.z.stack(combined=('time', 'traj')).values\n",
    "    new_lon = ds_back.lon.stack(combined=('time', 'traj')).values\n",
    "    new_lat = ds_back.lat.stack(combined=('time', 'traj')).values\n",
    "    new_h = ds_back.h.stack(combined=('time', 'traj')).values\n",
    "\n",
    "    new_ds = xr.Dataset(\n",
    "        {\n",
    "            'z': (['time'], new_z),\n",
    "            'lon': (['time'], new_lon),\n",
    "            'lat': (['timxtickse'], new_lat),\n",
    "            'h': (['time'], new_h),\n",
    "        },\n",
    "        coords={'time': new_time,},\n",
    "    )\n",
    "\n",
    "    new_ds['z'] = -new_ds.z\n",
    "\n",
    "\n",
    "    def plot_var(new_ds, ax, var_name, label):\n",
    "        var_data = new_ds[var_name]\n",
    "        df = var_data.to_dataframe()\n",
    "        df['Month'] = df.index.month\n",
    "\n",
    "        # reorder months\n",
    "        df_copy = df.copy()\n",
    "        for i in range(12):\n",
    "            df_copy.loc[df_copy['Month'] == xticks[i], 'Month'] = str(i+1)\n",
    "        df_copy['Month'] = df_copy['Month'].astype(int)\n",
    "\n",
    "        # Create a box-and-whisker plot using seaborn\n",
    "        ax = sns.boxplot(ax=ax, x='Month', y=var_name, data=df_copy, width=0.5, color='C1', flierprops = dict(marker='d', markersize=2))\n",
    "\n",
    "        # plot medians\n",
    "        monthly_median = var_data.groupby('time.month').median('time')\n",
    "        ax.plot(np.arange(0,12), reorder(monthly_median), marker='o', color='black')\n",
    "        ax.set_xticks(np.arange(12), string_numbers);\n",
    "        ax.set_ylabel(label);\n",
    "        #ax.set_yscale('log')\n",
    "\n",
    "    plot_var(new_ds, ax, \"z\", 'Depth (m)')\n",
    "\n",
    "    # ax.set_xticks([]);\n",
    "    # ax1.set_xticks([]);\n",
    "    ax.set_xlabel('');\n",
    "\n",
    "    #ax.text(-3, 350, 'a', fontsize=20)\n",
    "\n",
    "    ############# second row\n",
    "    monthly_mean_new_ds = new_ds.groupby('time.month').mean(dim='time')\n",
    "    monthly_std_new_ds = new_ds.groupby('time.month').std(dim='time')\n",
    "\n",
    "    order = [9,10,11,12,1,2,3,4,5,6,7,8]\n",
    "    order = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "\n",
    "    mean = reorder(monthly_mean_new_ds.z)\n",
    "    std = reorder(monthly_std_new_ds.z)\n",
    "    ax2.plot(order, mean, marker='o', label='Surface', color='C0')\n",
    "    ax2.fill_between(order, mean - std, mean + std, alpha=0.2, color='C0')\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Month')\n",
    "    ax2.set_xlabel('Month')\n",
    "    ax2.set_ylabel('Depth (m)')\n",
    "\n",
    "    ax2.set_ylim(-10, 200)\n",
    "    ax.set_ylim(-10,325)\n",
    "    ax2.set_xticks(np.arange(1,13), string_numbers);\n",
    "\n",
    "    #ax2.text(-2, 160, 'b', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b1ace-ba80-4bab-83ec-86e596730c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_back_water(index, close=False, save=False):\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "    order = [9,10,11,12,1,2,3,4,5,6,7,8]\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "    for t in range(12):\n",
    "        ax = fig.add_subplot(2, 6, t+1, projection=ccrs.PlateCarree())\n",
    "        ax.set_extent([17, 18.5, -33.5, -31], crs=ccrs.PlateCarree())\n",
    "        ax.add_feature(cfeature.LAND)\n",
    "        if t in [0,6]:\n",
    "            ax.set_yticks(np.arange(-33.5, -30.5, 0.5), crs=ccrs.PlateCarree())\n",
    "            lat_formatter = LatitudeFormatter()\n",
    "            ax.yaxis.set_major_formatter(lat_formatter)  \n",
    "        if t >= 6:\n",
    "            ax.set_xticks(np.arange(17, 18.5, 0.5), crs=ccrs.PlateCarree())\n",
    "            lon_formatter = LongitudeFormatter(zero_direction_label=False)\n",
    "            ax.xaxis.set_major_formatter(lon_formatter)\n",
    "        \n",
    "        # contour\n",
    "        contours = ax.contour(da.lon_rho, da.lat_rho, da.isel(time=0).h, \n",
    "                              levels=5, colors='black', linewidths=2, alpha=0.6, transform=ccrs.PlateCarree())\n",
    "        plt.clabel(contours, inline=True, fontsize=12)\n",
    "\n",
    "        #plt.contourf(tlong, tlat, da.zeta.isel(time=160), levels=15)\n",
    "        #plt.colorbar(label='Sea surface height (m)')\n",
    "\n",
    "        month = order[t]\n",
    "        tim = f'{month:02d}'\n",
    "        ds_back_ = ds_back_30days.sel(num_days_back= index, time=ds_back_30days['time.month'] == month)\n",
    "        plt.scatter(ds_back_.lon, ds_back_.lat, s=3, c=-ds_back_.z, vmin=0, vmax=300, cmap='viridis_r')\n",
    "        #plt.colorbar(shrink=1, label='Depth (m)')\n",
    "        plt.title(tim)\n",
    "\n",
    "        # coordinate of 70 m mooring\n",
    "        moor70m = [18.183, -32.329]\n",
    "        moor20m = [18.318, -32.292]\n",
    "        plt.scatter(moor70m[0], moor70m[1], s=30, marker='*',c='r')\n",
    "        \n",
    "        if t==1:\n",
    "            plt.text(19.2, -30.6, f'{index:02d} days back-in-time', fontsize=18)\n",
    "\n",
    "    def add_colorbar(x0, y0, vmin, vmax, label, cmap_label=\"viridis_r\"):\n",
    "        '''\n",
    "        x0, y0: start location for the colorbar\n",
    "        vmin, vmax: range of the colorbar\n",
    "        label: label of the colorbar'\n",
    "        '''\n",
    "        cax = fig.add_axes([x0, y0, 0.015, 0.5])  # [x0, y0, width, height]\n",
    "        cmap = plt.colormaps[cmap_label]\n",
    "        normalize = plt.Normalize(vmin=vmin, vmax=vmax)  # Normalize the color values\n",
    "        sm = cm.ScalarMappable(cmap=cmap, norm=normalize)\n",
    "        cbar = fig.colorbar(sm, cax=cax, shrink=0.9, label=label, orientation='vertical')\n",
    "        cbar.ax.tick_params(labelsize=14)\n",
    "\n",
    "    add_colorbar(0.92, 0.25, 0, 300, 'Depth (m)')\n",
    "    plt.subplots_adjust(wspace=0.06, hspace=0.04)\n",
    "    \n",
    "    # ax1 = fig.add_axes([1.02, 0.55, 0.2, 0.3]) # [left, bottom, width, height]\n",
    "    # ax2 = fig.add_axes([1.02, 0.2, 0.2, 0.3])\n",
    "    \n",
    "    ax1 = fig.add_axes([0.13, -0.35, 0.34, 0.4]) # [left, bottom, width, height]\n",
    "    ax2 = fig.add_axes([0.56, -0.35, 0.34, 0.4])\n",
    "    \n",
    "    # First map (upper-left of the 12)\n",
    "    fig.axes[0].text(\n",
    "        -0.15, 1.15, \"a\", transform=fig.axes[0].transAxes,\n",
    "        fontsize=20, fontweight=\"bold\", va=\"top\", ha=\"left\"\n",
    "    )\n",
    "\n",
    "    # Bottom row\n",
    "    ax1.text(\n",
    "        -0.15, 1.05, \"b\", transform=ax1.transAxes,\n",
    "        fontsize=20, fontweight=\"bold\",va=\"top\", ha=\"left\"\n",
    "    )\n",
    "    ax2.text(\n",
    "        -0.15, 1.05, \"c\", transform=ax2.transAxes,\n",
    "        fontsize=20,  fontweight=\"bold\",va=\"top\", ha=\"left\"\n",
    "    )\n",
    "\n",
    "\n",
    "    plot_depth_mean(index, ax1, ax2)\n",
    "    \n",
    "    if close == True:\n",
    "        plt.close()\n",
    "    \n",
    "    if save == True:\n",
    "        fig.savefig(f'./figures/figs2movie/backward_watermass_70m/backward_watermass_70m_{index:02}d_clim_together.png', bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293164ca-d883-474e-bff1-fc9285536613",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "movie_back_water(30, close=False, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda1e38-98dc-4486-aa6c-9b56e3bb6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for t in range(1, len(ds_back_30days.num_days_back.values)+1):\n",
    "    print(t)\n",
    "    movie_back_water(t, close=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffcd61-481a-42e6-b2d5-6c1f6559205f",
   "metadata": {},
   "source": [
    "# Figure S8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29eb16-bdf2-4398-96c5-3885f84e127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_stra.N2_int.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c82d39-297d-4fe9-919c-a8f55ab7672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = ns_mdl10m.svstr.values\n",
    "N = ds_stra.N2_int.values\n",
    "rho0 = 1025\n",
    "\n",
    "omega = 7.292115e-5  # (Groten, 2004)                  [ radians/s ]\n",
    "lat = -32\n",
    "f = np.abs(2*omega*np.sin(lat))\n",
    "\n",
    "\n",
    "d = 4.83 + 9.13*np.sqrt(tau/(rho0*N*f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8220d-d6db-4dd4-be49-98c0352ae84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_stra[\"source_depth\"] = (\"time\", d)\n",
    "ds_stra[\"wind\"] = (\"time\", ns_mdl10m.svstr.values)\n",
    "\n",
    "ds_stra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4fe096-89a0-4ac3-ab6e-d3f364c0b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_stra_median = ds_stra.groupby('time.month').median(dim='time')\n",
    "ds_stra_mean = ds_stra.groupby('time.month').mean(dim='time')\n",
    "ds_stra_std = ds_stra.groupby('time.month').std(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa282435-7dff-46d1-b54b-c519ff12ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "var_name = 'source_depth'\n",
    "var_data = ds_stra[var_name]\n",
    "df = var_data.to_dataframe()\n",
    "df['Month'] = df.index.month\n",
    "\n",
    "# reorder months\n",
    "df_copy = df.copy()\n",
    "for i in range(12):\n",
    "    df_copy.loc[df_copy['Month'] == xticks[i], 'Month'] = str(i+1)\n",
    "df_copy['Month'] = df_copy['Month'].astype(int)\n",
    "\n",
    "# Create a box-and-whisker plot using seaborn\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = sns.boxplot(x='Month', y=var_name, data=df_copy, width=0.5, color='gray')\n",
    "\n",
    "# plot medians\n",
    "monthly_median = var_data.groupby('time.month').median('time')\n",
    "plt.plot(np.arange(0,12), reorder(monthly_median), marker='o', color='black')\n",
    "\n",
    "N_monthly_median = monthly_median\n",
    "\n",
    "# Customize the plot labels and title\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Upwelling source depth (m)')\n",
    "plt.xticks(np.arange(12), string_numbers);\n",
    "#plt.yticks(np.arange(0,18,2));\n",
    "#plt.title(f'Box-and-Whisker Plot for {var_name} by Month')\n",
    "#plt.ylim(1,12)\n",
    "#fig.savefig('./figures/figure_S8.png',bbox_inches='tight',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19486161-523a-442b-86e9-3f7c6ba0cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_stra_median.wind.plot(color='b', marker='o')\n",
    "ds_stra_mean.wind.plot(color='r', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9ef2a-2e75-49db-9595-049795d1f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_stra_median.N2_int.plot(color='b', marker='^')\n",
    "ds_stra_mean.N2_int.plot(color='r', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4646a9f-2ec5-4f7f-9e1b-a17824c27492",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mean = 4.83 + 9.13*np.sqrt(ds_stra_mean.wind/(rho0 * ds_stra_mean.N2_int * f))\n",
    "d_median = 4.83 + 9.13*np.sqrt(ds_stra_median.wind/(rho0 * ds_stra_median.N2_int * f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736b4c9-59ca-49f6-8e33-7bcd2fc4f344",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,12), reorder(d_median), marker='o', color='b')\n",
    "plt.plot(np.arange(0,12), reorder(d_mean), marker='o', color='r')\n",
    "\n",
    "plt.xticks(np.arange(12), string_numbers);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38588c44-7c2d-4445-a7a5-8d13dec7e075",
   "metadata": {},
   "source": [
    "# Figure S7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb1f64-7eb6-4d99-a9a8-2726c57b180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sheet = pd.read_excel('./data/Grant_2022_data.xlsx', sheet_name='cleaned')\n",
    "\n",
    "# fill in the nans in Time array\n",
    "original_time = df_sheet['Time'].values\n",
    "for i in range(len(original_time)):\n",
    "    if str(original_time[i]) == 'NaT':\n",
    "        original_time[i] = original_time[i-1]\n",
    "\n",
    "df_sheet['Time'] = original_time\n",
    "\n",
    "df_sheet.columns = ['time', 'Depth', 'Resp', 'NCP', 'GCP'] # rename\n",
    "\n",
    "for i in range(len(df_sheet)):\n",
    "    if df_sheet['Depth'][i] == 14:\n",
    "        df_sheet['Depth'][i] = 15\n",
    "\n",
    "df_sheet.set_index('time', inplace=True)\n",
    "\n",
    "# Convert the DataFrame to an xarray Dataset\n",
    "ds = xr.Dataset.from_dataframe(df_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a27088-ce84-42cd-b461-aac728da2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsurface: depth > 8 or depth > 15\n",
    "ds_sub = ds.where(ds.Depth>5, drop=True)\n",
    "mean = ds_sub.groupby('time.month').mean(dim='time')\n",
    "std = ds_sub.groupby('time.month').std(dim='time')\n",
    "\n",
    "uni_date = np.unique(ds_sub.time)\n",
    "\n",
    "Resp_int = np.zeros(uni_date.shape)\n",
    "NCP_int = np.zeros(uni_date.shape)\n",
    "GCP_int = np.zeros(uni_date.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4248bf35-56c8-45f2-a899-e3d26e99e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over different depth levels\n",
    "for i in range(len(uni_date)):\n",
    "    \n",
    "    ds_ = ds_sub.sel(time=uni_date[i]) # select a profile\n",
    "    \n",
    "    if ds_.Depth.size <= 2:\n",
    "        Resp_int[i] = ds_.Resp.mean()\n",
    "        NCP_int[i] = ds_.NCP.mean()\n",
    "        GCP_int[i] = ds_.GCP.mean()\n",
    "    else:\n",
    "        resp = ds_.Resp.values\n",
    "        NCP = ds_.NCP.values\n",
    "        GCP = ds_.GCP.values\n",
    "        depth = ds_.Depth.values\n",
    "        \n",
    "        Resp_int[i] = ((depth[1] - depth[0]) * (resp[0] + resp[1])/2 + (depth[2] - depth[1]) * (resp[1] + resp[2])/2) / (depth[2] - depth[1])\n",
    "        NCP_int[i] = ((depth[1] - depth[0]) * (NCP[0] + NCP[1])/2 + (depth[2] - depth[1]) * (NCP[1] + NCP[2])/2) / (depth[2] - depth[1])\n",
    "        GCP_int[i] = ((depth[1] - depth[0]) * (GCP[0] + GCP[1])/2 + (depth[2] - depth[1]) * (GCP[1] + GCP[2])/2) / (depth[2] - depth[1])\n",
    "\n",
    "ds_int = xr.Dataset(\n",
    "    {\n",
    "        'Resp': (['time'], Resp_int*44.7),\n",
    "        'NCP': (['time'], NCP_int*44.7),\n",
    "        'GCP': (['time'], GCP_int*44.7),\n",
    "    },\n",
    "    coords={'time': uni_date,},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741efbbb-50b5-4883-94fa-9b56e3285cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(mean):\n",
    "    arr = mean\n",
    "    arr_ = np.insert(arr, 5, np.nan)\n",
    "    \n",
    "    return np.concatenate((arr_[-4:], arr_[:-4]))\n",
    "\n",
    "xticks = np.concatenate((np.arange(9,13), np.arange(1,9)))\n",
    "string_numbers = [str(xt) for xt in xticks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0b2d3-1123-4959-9130-f0a9f853d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = ds_int.groupby('time.month').mean(dim='time')\n",
    "std = ds_int.groupby('time.month').std(dim='time')\n",
    "\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "# Assuming `dataset` is your xarray dataset and `variable_name` is the name of the variable you want to plot\n",
    "variable = ds_int.Resp\n",
    "\n",
    "# Extract months from the time dimension\n",
    "months = pd.to_datetime(variable['time'].values).month\n",
    "\n",
    "# Adjust the months to wrap around starting from September (month 9)\n",
    "adjusted_months = []\n",
    "for i in range(len(months)):\n",
    "    if months[i] > 8:\n",
    "        adjusted_months.append(months[i] - 8)\n",
    "    else:\n",
    "        adjusted_months.append(months[i] - 8 + 12)\n",
    "        \n",
    "\n",
    "# Plot scatter\n",
    "plt.scatter(adjusted_months, variable.values, s=20,c='k')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Respiration rate (µmol O$_2$ L$^{-1}$ day$^{-1}$)')\n",
    "\n",
    "# Customize x-axis ticks and labels\n",
    "plt.xticks(ticks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "           labels=[str(i) for i in [9,10,11,12,1,2,3,4,5,6,7,8]]);\n",
    "\n",
    "def get_mean_std(months):\n",
    "    '''\n",
    "    months: [9,10,11]\n",
    "    '''\n",
    "    mean_R = mean.Resp.sel(month=months).values.mean()\n",
    "    std_R = mean.Resp.sel(month=months).values.std()\n",
    "    \n",
    "    return mean_R, std_R\n",
    "    \n",
    "# plt.errorbar(0 * 3 + 2, mean_R, yerr=std_R, fmt='o', color='red', capsize=5, label=f' Mean ± Std')\n",
    "season_labels = ['s','ss','sdd','sddd']\n",
    "season_labels = [2,5,8,11]\n",
    "mean_values = [get_mean_std([9,10,11])[0], get_mean_std([12,1,2])[0], get_mean_std([3,4,5])[0], get_mean_std([7,8])[0]]\n",
    "std_values = [get_mean_std([9,10,11])[1], get_mean_std([12,1,2])[1], get_mean_std([3,4,5])[1], get_mean_std([7,8])[1]]\n",
    "plt.bar(season_labels, mean_values, yerr=std_values, capsize=5, color='skyblue', ecolor='blue', \\\n",
    "        alpha=0.7, width=2, linewidth=3,)\n",
    "\n",
    "fig.savefig('./figures/figure_S7.png', bbox_inches='tight', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b29962-5bd4-45d9-800d-3e7034b9ef41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opendrift",
   "language": "python",
   "name": "opendrift"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
